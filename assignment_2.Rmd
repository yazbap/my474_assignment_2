---
title: "Assignment #2"
date: "February 26, 2024"
output: html_document
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(echo = FALSE)
```

## Exercise 1

What is the difference between train and train 2?

- Train 2 has an additional parameter `m` with the default set to 0.9. It also contains an additional vector `v` which has the same number of elements as coefficients in the model. These additional features turns this into a stochastic gradient descent with momentum algorithm. In these types of algorithms, the `v` vector stores the history of the magnitude of the parameter update equation for the kth coefficient which is done on the line `v[k] <- m*v[k] + l_rate*(yhat_i - y[i])*row_vec[k]`. The `m` parameter controls how much weight previous updates have on the current update. In this case, a value of 0.9 means that previous updates has a strong influence on the current update. 

How might this affect the performance of the algorithm?

To understand why adding momentum may be necessary, we first have to understand potential issues that can come up with SGD. A problem with SGD is that the progression toward the minima can move in inappropriate directions depending on the points sampled during the search which can can slow down progress. Adding previous update values as a factor can increase or decrease the magnitude of the next step and guide its direction. This can result in fewer steps reaching the minima. Momentum is helpful in cases where:

- the objective function has a lot of curvature meaning that the gradient may change a lot over small regions of the search space as the momentum will guide the algorithm with greater velocity toward the minima

- the gradient has a high variance as the momentum will provide more context on where the algorithm should go

- when the search space is flat or nearly flat as the momentum allows the search to progress in the same direction as before the flat spot and helpfully cross the flat region.

Demonstrate your argument by including a coded example, comparing this algorithm, and point to elements of the output that help illustrate your answer.

As shown in the plots for train_1, the algorithm we made in class and train_2, the algorithm given in this assignment, the second has more erratic behavior, while the former has a smoother line around the final MSE and NLL.

Critique the function more generally. What are some of the general constraints or limitations of the implementation? Are there any ways you could improve it further?

General constraints

- The amount of the momentum that contributes to the algorithm in each epoch is the same. if we vary how much momentum contributes to the next step, given how much loss was in the last epoch we can have a smoother line toward the appropriate next step.

```{r train}
# Define the train function
train <- function(X, y, l_rate, epochs) {
  coefs <- rep(0, ncol(X))
  MSE_list <- vector("numeric", length = epochs)  # List to store MSE for each epoch
  NLL_list <- vector("numeric", length = epochs)  # List to store NLL for each epoch
  
  for (b in 1:epochs) {
    for (i in sample(1:nrow(X))) { 
      row_vec <- as.numeric(X[i,])
      
      yhat_i <- predict_row(row_vec, coefficients = coefs)
      
      # Update coefficients using gradient descent
      coefs <- sapply(1:length(coefs), function (k) {
        coefs[k] - l_rate * (yhat_i - y[i]) * row_vec[k]
      })
    }
    
    # Calculate current predictions
    yhat <- apply(X, 1, predict_row, coefficients = coefs)
    
    # Calculate MSE and NLL
    MSE_epoch <- MSE(y, yhat)
    NLL_epoch <- NLL(y, yhat)
    
    # Store MSE and NLL for this epoch
    MSE_list[b] <- MSE_epoch
    NLL_list[b] <- NLL_epoch
  }
  
  # Set up the multi-panel layout
  par(mfrow = c(1, 2))
  
  # Plot the MSE and NLL over epochs
  plot(1:epochs, MSE_list, type = "l", xlab = "Epoch", ylab = "MSE", main = "Train_1 MSE over Epochs")
  plot(1:epochs, NLL_list, type = "l", xlab = "Epoch", ylab = "NLL", main = "Train_1 NLL over Epochs")
  
  return(coefs)  # Output the final estimates
}
```


```{r train2}
# Define the train function
train2 <- function(X, y, l_rate, m = 0.9, epochs) {
  coefs <- rep(0, ncol(X))
  v <- rep(0, ncol(X)) # initialize v to 0
  MSE_list <- vector("numeric", length = epochs)  # List to store MSE for each epoch
  NLL_list <- vector("numeric", length = epochs)  # List to store NLL for each epoch
  
  for (b in 1:epochs) {
    for (i in sample(1:nrow(X))) { 
      row_vec <- as.numeric(X[i,])
      
      yhat_i <- predict_row(row_vec, coefficients = coefs)
      
      # Update coefficients using gradient descent
       for(k in 1:length(coefs)) { # loop over each coefficient
        
        v[k] <- m*v[k] + l_rate*(yhat_i - y[i])*row_vec[k] 
        
        coefs[k] <- coefs[k] - v[k] # update the coefficient
      }
    }
    
    # Calculate current predictions
    yhat <- apply(X, 1, predict_row, coefficients = coefs)
    
    # Calculate MSE and NLL
    MSE_epoch <- MSE(y, yhat)
    NLL_epoch <- NLL(y, yhat)
    
    # Store MSE and NLL for this epoch
    MSE_list[b] <- MSE_epoch
    NLL_list[b] <- NLL_epoch
    
  }
  
  # Set up the multi-panel layout
  par(mfrow = c(1, 2))
  
  # Plot the MSE and NLL over epochs
  plot(1:epochs, MSE_list, type = "l", xlab = "Epoch", ylab = "MSE", main = "Train_2 MSE over Epochs")
  plot(1:epochs, NLL_list, type = "l", xlab = "Epoch", ylab = "NLL", main = "Train_2 NLL over Epochs")
  
  return(coefs)  # Output the final estimates
}
```

```{r}
set.seed(89)

genX <- function(n) {
  return(
    data.frame(X0 = 1,
               X1 = runif(n,-5,5),
               X2 = runif(n,-2,2))
  )
}

genY <- function(X) {
  Ylin <- 3*X$X0 + 1*X$X1 - 2*X$X2 + rnorm(nrow(X),0,0.05) 
  Yp <- 1/(1+exp(-Ylin))
  Y <- rbinom(nrow(X),1,Yp)
  return(Y)
}

predict_row <- function(row, coefficients) {
  pred_terms <- row*coefficients # get the values of the individual linear terms
  yhat <- sum(pred_terms) # sum these up (i.e. \beta_0 + \beta_1X_1 + ...
  return(1/(1+exp(-yhat))) # convert to probabilities
}

X <- genX(1000)
y <- genY(X)
```


```{r, echo = TRUE}
coef_model <- train(X = X, y = y, l_rate = 0.01, epochs = 50)
```

```{r, echo = TRUE}
coef_model2 <- train2(X = X, y = y, l_rate = 0.01, m = 0.9, epochs = 50)
```


## Exercise 2

Consider the following research context:

An analyst has a dataset consisting of a continuous outcome variable (y), and a single continuous predictor variable (x). They are interested in generating the most predictive model they can of the form y=f(x)+λ∗R(f)
, where f is a linear model. They have at their disposal the ability to adjust both λ and to include polynomials of X up to the 7th order. The analyst does not have access to any in-built cross-validation functions (for example, cv.glmnet()). Your task is to write a function that:

Takes in an outcome y and explanatory variable x (both are continuous, and supplied as separate vectors)
Identifies the optimal combination of both λ and f in a principled way
Prints, as separate lines:
The optimal model form
The test loss of the optimal model
Returns the final trained model
Your answer should be a single code chunk which contains the function. If you make any notable choices while building this function, you may describe these under the code chunk.

Notes: * Your answer will be assessed by running the function on unseen data, which conforms to the description above * Code comments should be used to clearly annotate your function, and to draw attention to any notable features of your implementation

```{r}
ridgeLoss <- function(ytrue, yhat, coefficients, lambda) {
  nll <- NLL(ytrue, yhat)
  l2_penalty <- lambda*sum(coefficients^2)
  return(nll + l2_penalty)
}
```


```{r}
#set lambda values to loop through
lambdas <- c(0.0001, 0.001, 0.01, 0.1, 1, 10)

#set polynomial degrees to loop through
poly_degrees <- seq(1, 7, by=1)

#set the number of folds
K <- 10

optimal_model <- function(x,y){
  # Initialize best lambda, degree, model and test loss to NULL to store optimal parameters and test loss
  best_lambda <- NULL
  best_degree <- NULL
  best_model <- NULL
  best_loss <- Inf
  
  #for each lambda value
  for (lambdas in lambdas){
    
    #for each polynomial degree
    for (degree in degrees){
      #transform the x data to this particular polynomial
      x_poly <- poly(x, degree)
  
      #assign each observation to a fold
      fold_id <- sample(rep(1:K, each = nrow(X)/K))
      #set the total loss to 0 for this loop
      total_loss <- 0
      
      #for each fold
      for (k in 1:K){
        #assign the validation data for X
        val_X <- X[fold_id == k,]
        
        #assign the training data for X
        train_X <- X[fold_id != k,]
  
        #assign the validation data for y
        val_y <- y[fold_id == k]
        
        #assign the training data for y
        train_y <- y[fold_id != k]
  
        #create a model with this particular combination of polynomial and lambda using ridge regression
        k_mod <- glmnet(train_X, train_y, family = "gaussian", lambda = lambda, alpha = 0)
  
        #make predictions with the model
        yhat_k <- predict(k_mod, newx = as.matrix(val_X), type = "response")
  
        #calculate the loss
        k_loss <- ridgeLoss(val_y, yhat_k, coef(k_mod)[-1], lambda)
  
        #if the loss is less than the best test loss
        if (k_loss < best_loss){
          #set the best loss as this value
          best_loss <- k_loss
          
          #set the best degree to this degree
          best_degree <- degree
          
          #set the best lambda to this lambda
          best_lambda <- lambda
          
          #set the best model as this model
          best_model <- k_mod
        }
      }
      
    }
      
    #set the model with all the data
    best_model <- glmnet(poly(x, best_degree), 
                         y, 
                         family = "gaussian", 
                         lambda = best_lambda, 
                         alpha = 0)
  
    #Print the optimal model
    cat("The best model is: ", best_model)
  
    #Print the test loss of the optimal model
    cat("The loss of the optimal model is: ", best_loss)
  
    #return the model with the lowest loss
    return(best_model)
}

```



```{r}
find_optimal_model <- function(y, x) {
    # Arguments:
    # y (numeric vector): Vector of continuous outcome variable.
    # x (numeric vector): Vector of continuous predictor variable.
    
    # Returns:
    # final_model: Trained linear regression model with optimal parameters.
    
    # Initialize variables to store optimal parameters and test loss
    best_lambda <- NULL
    best_degree <- NULL
    best_test_loss <- Inf
    final_model <- NULL
    
    # Loop through lambda values
    for (lambd in c(0.0001, 0.001, 0.01, 0.1, 1, 10)) {
      #set fold id
      #set total loss
        
        # Loop through polynomial degrees
        for (degree in 1:7) {
          
            # Fit polynomial regression model with ridge regularization
            model <- lm(y ~ x_poly + 0)  # + 0 to remove intercept
            model <- lm(y ~ x_poly, lambda = lambd)  # ridge regularization
            
            # Calculate current error
            yhat <- apply(X, 1, predict_row, coefficients = coefs)
            loss_epoch <- ridgeLoss(y, yhat, coefs, lambda)
            
            # report the error to the user
            message(
              paste0(
                "Iteration ", b ,"/",epochs," | Loss = ", round(loss_epoch,5)
              )
            )
            
            # Update best parameters if test loss improves
            if (test_loss < best_test_loss) {
                best_lambda <- lambd
                best_degree <- degree
                best_test_loss <- test_loss
                final_model <- model
        }
        }
      
    }
    
    # Print optimal model form and test loss
    
    # Fit final model with optimal parameters
    # final_model <- ...
    
    # Return final trained model
    }
}

```

## Exercise 3

We have provided you with a dataset called civil_wars.RData, which records for each country and every year, whether that country was engaged in a civil war. The data was taken from Kaufman et al’s (2019) replication materials, which focuses on the use of boosted decision trees:

Kaufman AR, Kraft P, Sen M. Improving Supreme Court Forecasting Using Boosted Decision Trees. Political Analysis. 2019;27(3):381-387. doi:10.1017/pan.2018.59

To read this dataset you need to call load(civil_wars.RData), which will load the data as a variable called civwars into your environment. When you view the data in R (i.e. View(civwars)), you will see the variable descriptions under the variable names. We have removed country names from the dataset intentionally, so that all variables are numerical, and imputed any missing values.

Your task is to build a model to predict civil war. You should use the data however you see fit, and you may use any class of model we have considered (including any already covered in this assignment).

Your answer should be a report of between 250-500 words that a) introduces the problem, b) summarises any decisions you made about training the model, and c) demonstrate your final trained model’s performance. You may use (well-formatted) charts to help illustrate your claims.

Note: you do not need to submit the trained model object, and may use any R packages/functions in this task.

The models we learned in class so far are KNN, Trees and LASSO and Ridge regression. KNN would not be good in this case because the model because it does not typically work well with data with high dimensions. Trees also would not work because they are rarely the best in terms of prediction. 

Is LASSO or ridge better? In this case LASSO is the best model as assessed by a paper by Ward, Greenhill and Bakke Reference Ward, Greenhill and Bakke (2010) in which they state ..."when it comes to choosing a model that best predicts the occurrence of civil war, a very parsimonious model can often fare better than one that contains a relatively large number of statistically-significant variables."

```{r}
load("civil_wars.RData")

View(civwars)

predict_civ_war <- function(){
  # X = training data
  # y = true outcomes
  # l_rate = learning rate
  # epochs = number of SGD iterations through X
  # lambda = extent of L2 regularization
  
  #test different values of lambda
  
  # instantiate glmnet model
  
  #for all epochs
    #sample rows in random order
      #make row easier to handle
      #predict row with coefficients
      #
}

#Options:
  #glmnet
  #trees
    #not the best predictive power
  #knn
    #not good on data with a lot of dimensions
  #glm
```

This document contains the necessary commands and layout to meet the formatting requirements for MY472. You should use the template.Rmd file as the basis for your own answers to the assigned exercises.

## Formatting requirements

For clarity, the formatting requirements for each assignment are:

* You must write in **full sentences**, as you would in a report or academic piece of writing
  
  * If the exercise requires generating a table or figure, you should include at least one sentence introducing and explaining it. E.g. "Table 1 reports the cross-validation test scores for a grid search of $\lambda$ values in the LASSO model."

* Unless stated otherwise, all code used to answer the exercises should be included as a code appendix at the end of the script. This formatting can be achieved by following the guidance in the template.Rmd file we provide on Moodle

* All code should be annotated with comments, to help the marker understand what you have done

* Your output should be replicable. Any result/table/figure that cannot be traced back to your code will not be marked

## Example of in-line figures without code

We achieve the formatting requirements in two-steps: 

  1) In the `setup` chunk, add `knitr::opts_chunk$set(echo = FALSE)` so that code is not included (echoed) by default in code chunks; 
  2) Add a specific code chunk at the end of the file to collect and print *all* the code in the Rmarkdown file. You can see this code at the bottom of this template. If you use this template for your assignments, do not delete the final code chunk!

Below, we use a code chunk to generate random data and include a scatter plot in-line. The code used to generate this chart is only reported at the end of the document. 

```{r plot_example}
set.seed(89) # set a seed for R's psuedo-randomiser, for replicability.
x <- rnorm(100) # randomly draw 100 obs from normal distribution, save as object
y <- rnorm(100) 
plot(x,y) # two-way scatterplot using R's default plotting
```

In specific instances, however, you may be directed to report your code in-line (or you may want to do this to illustrate a specific point). In these cases, we can override the default behaviour by adding the chunk option `echo = TRUE` to a specific R chunk. When `echo=TRUE`, your code is presented in-line with any output displayed afterwards. The same code will also be included in the appendix at the bottom of the document (which is fine).

```{r echo_example, echo=TRUE}
# {[language] [chunk_name], [chunk_options]}
# here we use echo=TRUE to override our global options and make the chunk appear exactly here. 

print("This code chunk is visible in this section.")
```

## Appendix: All code in this assignment

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE} 
# this chunk generates the complete code appendix. 
# eval=FALSE tells R not to run (``evaluate'') the code here (it was already run before).
```