---
title: "Assignment #2"
date: "February 26, 2024"
output: html_document
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(glmnet)
library(pROC)

```

## Exercise 1

#### Algorithm Differences

`Train2()` differs from the `train` algorithm we considered in class in that it has an additional parameter `m` with the default set to 0.9. It also contains an additional vector `v` which has the same number of elements as coefficients in the model. These additional features turns this into a stochastic gradient descent with momentum algorithm. In these types of algorithms, the `v` vector stores the history of the magnitude of the parameter update equation for the kth coefficient which is done on the line `v[k] <- m*v[k] + l_rate*(yhat_i - y[i])*row_vec[k]`. The `m` parameter controls how much weight previous updates have on the current update. In this case, a value of 0.9 means that previous updates have a strong influence on the current update. 

To understand why adding momentum may be necessary, we first have to understand potential issues that can come up with SGD. A problem with SGD is that the progression toward the minima can move in inappropriate directions depending on the points sampled during the search which can can slow down progress. Adding previous update values as a factor can increase or decrease the magnitude of the next step and guide its direction. This can result in fewer steps reaching the minima. Momentum is helpful in cases where:

- The objective function has a lot of curvature meaning that the gradient may change a lot over small regions of the search space as the momentum will guide the algorithm with greater velocity toward the minima

- The gradient has a high variance, momentum will provide more context on where the algorithm should go

- When the search space is flat or, in other words, has a zero gradient, it typically indicates a local minimum (or maximum) of the function. If the optimization algorithm relies solely on the gradient, it might get stuck in such regions, unable to make progress towards finding the global minimum. Momentum allows the search to progress in the same direction as before the flat spot and ideally cross the flat region.

(Brownlee, 2021)

```{r functions}
#=========================================================
# Loss Functions
#=========================================================

MSE <- function(ytrue, yhat) {
  return(mean((ytrue - yhat)^2)) # Return mean squared error
}

NLL <- function(ytrue, yhat) {
  return(-sum(log((yhat^ytrue) * ((1 - yhat)^(1 - ytrue))))) # Return Negative Log Likelihood
}

ridgeLoss <- function(ytrue, yhat, coefficients, lambda) {
  mse <- MSE(ytrue, yhat) # Calculate mean squared error
  l2_penalty <- lambda*sum(coefficients^2) # Calculate ridge regression penalty
  return(mse + l2_penalty) # Return sum of mse and penalty
}

#=========================================================
# Train Functions
#=========================================================
train <- function(X, y, l_rate, epochs) {
  
  # Initialize coefficients to zeros
  coefs <- rep(0, ncol(X))
  
  # Lists to store MSE and NLL for each epoch
  MSE_list <- vector("numeric", length = epochs)
  NLL_list <- vector("numeric", length = epochs)
  
  # Loop through each epoch
  for (b in 1:epochs) {
    
    # Loop through each row of the data (in random order)
    for (i in sample(1:nrow(X))) { 
      
      # Extract the predictor values for the current row
      row_vec <- as.numeric(X[i,])
      
      # Predict the target variable for the current row
      yhat_i <- predict_row(row_vec, coefficients = coefs)
      
      # Update coefficients using gradient descent
      coefs <- sapply(1:length(coefs), function (k) {
        coefs[k] - l_rate * (yhat_i - y[i]) * row_vec[k]
      })
    }
    
    # Calculate predictions for all data points
    yhat <- apply(X, 1, predict_row, coefficients = coefs)
    
    # Calculate MSE and NLL for this epoch
    MSE_epoch <- MSE(y, yhat)
    NLL_epoch <- NLL(y, yhat)
    
    # Store MSE and NLL for this epoch
    MSE_list[b] <- MSE_epoch
    NLL_list[b] <- NLL_epoch
  }
  
  # Set up the multi-panel layout for plotting
  par(mfrow = c(1, 2))
  
  # Plot the MSE over epochs
  plot(1:epochs, MSE_list, type = "l", 
       xlab = "Epoch", 
       ylab = "MSE", 
       main = "Figure 1: train() MSE over Epochs")
  
  # Plot the NLL over epochs
  plot(1:epochs, NLL_list, type = "l", 
       xlab = "Epoch", 
       ylab = "NLL", 
       main = "Figure 2: train() NLL over Epochs")
  
  # Return the final estimates of coefficients
  return(coefs)
}

train2 <- function(X, y, l_rate, m = 0.9, epochs) {
  
  # Initialize coefficients to zeros
  coefs <- rep(0, ncol(X))
  
  # Initialize velocity to zeros
  v <- rep(0, ncol(X))
  
  # Lists to store MSE and NLL for each epoch
  MSE_list <- vector("numeric", length = epochs)
  NLL_list <- vector("numeric", length = epochs)
  
  # Loop through each epoch
  for (b in 1:epochs) {
    
    # Loop through each row of the data (in random order)
    for (i in sample(1:nrow(X))) { 
      
      # Extract the predictor values for the current row
      row_vec <- as.numeric(X[i,])
      
      # Predict the target variable for the current row
      yhat_i <- predict_row(row_vec, coefficients = coefs)
      
      # Update coefficients using gradient descent with momentum
      for(k in 1:length(coefs)) { # loop over each coefficient
        
        # Update velocity using momentum
        v[k] <- m * v[k] + l_rate * (yhat_i - y[i]) * row_vec[k] 
        
        # Update the coefficient using the velocity
        coefs[k] <- coefs[k] - v[k] # update the coefficient
      }
    }
    
    # Calculate predictions for all data points
    yhat <- apply(X, 1, predict_row, coefficients = coefs)
    
    # Calculate MSE and NLL for this epoch
    MSE_epoch <- MSE(y, yhat)
    NLL_epoch <- NLL(y, yhat)
    
    # Store MSE and NLL for this epoch
    MSE_list[b] <- MSE_epoch
    NLL_list[b] <- NLL_epoch
    
  }
  
  # Set up the multi-panel layout for plotting
  par(mfrow = c(1, 2))
  
  # Plot the MSE and NLL over epochs
  plot(1:epochs, MSE_list, type = "l", 
       xlab = "Epoch", ylab = "MSE", 
       main = "Figure 3: train2() MSE over Epochs")
  
  plot(1:epochs, NLL_list, type = "l", 
       xlab = "Epoch", ylab = "NLL", 
       main = "Figure 4: train2() NLL over Epochs")
  
  return(coefs)  # Output the final estimates
}

#=========================================================
# Data Simulation Functions
#=========================================================
genX_ex1 <- function(n) {
  return(
    data.frame(X0 = 1,  # Intercept term
               X1 = runif(n, -5, 5),  # Random uniform values for X1 between -5 and 5
               X2 = runif(n, -2, 2))  # Random uniform values for X2 between -2 and 2
  )
}

genY_ex1 <- function(X) {
  
  # Linear relationship between features and target with added noise
  Ylin <- 3*X$X0 + 1*X$X1 - 2*X$X2 + rnorm(nrow(X), 0, 0.05)
  
  # Apply logistic function to convert linear values to probabilities
  Yp <- 1/(1+exp(-Ylin))
  
  # Generate binary outcomes based on the probabilities
  Y <- rbinom(nrow(X), 1, Yp)
  
  return(Y)  # Return the generated target variable
}

# Define a function to generate example data with one feature
genX_ex2 <- function(n) {
  return (rnorm(n, 0, 1))  # Generate random normal values for X
}


genY_ex2 <- function(X, random_coefs) {
  Ylin <- random_coefs[1] * X +  # Linear combination of features with random coefficients
     random_coefs[2] * X^2 +
     random_coefs[3] * X^3 +
     random_coefs[4] * X^4 +
     random_coefs[5] * X^5 +
     random_coefs[6] * X^6 +
     random_coefs[7] * X^7 +
     rnorm(length(X), mean = 0, sd = 0.5)  # Add random noise
  
  return(Ylin)  # Return the generated target variable
}

# Define a function to predict the target variable for a single row of data
predict_row <- function(row, coefficients) {
  
  # Multiply each feature value by its corresponding coefficient
  pred_terms <- row * coefficients
  
  # Sum up the products to get the linear prediction
  yhat <- sum(pred_terms)
  
  # Apply logistic function to convert linear prediction to probabilities
  return(1/(1+exp(-yhat)))
}

```



```{r}
#=========================================================
# Exercise 1
#=========================================================
set.seed(89) # Set random seed

X <- genX_ex1(1000) # Generate x values
y <- genY_ex1(X) # Generate y values

``` 

#### Error Behavior

As shown in Figures 1 and 2, `train()` is quickly able to lower both the Mean squared error (MSE) and Negative Log Likelihood (NLL) very dramaically within the first 10 epochs, then tends to stay within a relatively small interval which helps us come to the conclusion of what the minimum values of these errors are. In showing this plot, `train()` shows us how SGD makes larger steps toward the minima when it is farther away and gradually takes smaller steps as we approach the ideal coefficients for our model. 

Figures 3 and 4 show the behavior of the errors for `train2()` which is much more erratic than `train()`. This shows us that momentum may bypass the ideal points for the coefficients and ultimately lead to a longer time needed for training, or we can also say that momentum should be used with only certain kinds of data. 

```{r fig.width = 13, fig.height = 7}
coef_model <- train(X = X, y = y, l_rate = 0.01, epochs = 50) # Train and produce plots
```

```{r fig.width = 13, fig.height = 7}
coef_model2 <- train2(X = X, y = y, l_rate = 0.01, m = 0.9, epochs = 50) # Train and produce plots
```

#### General Constraints

Unavoidable Constraints:

- The utilization of momentum in optimization processes unavoidably increases memory requirements. This arises from the introduction of an additional term and hyperparameter that necessitate storage and ongoing updates. Depending on the storage you have avaialable and the size of the problem, this may or not may be any issue, but in using more memory, we also obain opportunities for potentially optimizing our approach more effectively.

Algorithmic Improvements:

- In the train2() function, the uniform contribution of momentum to the algorithm in each epoch may limit the optimization process. By introducing variability in the momentum's contribution to subsequent steps, we can achieve a more adaptive adjustment of the update size for model parameters. Taking inspiration from Nesterov Momentum, we can refine this approach further. Instead of solely updating the kth element of the v vector based on the partial derivative of the coefficient at its current position, we can calculate the partial derivative of the coefficient at the hypothetical new position it would attain if we calculated the velocity as per the `v[k]` update line in `train2()`. This anticipatory calculation allows us to better anticipate shifts in the gradient, particularly when approaching or surpassing minima. In scenarios where the partial derivative indicates that the minima have been surpassed, we have the opportunity to dampen the momentum's influence on the update. This adaptive adjustment ensures that when we make a "mistake" in overshooting the global minima, we can correct it using an adaptive momentum scheme.

- Alternatively, we can also add a weight decay term to the algorithm in which we store more data on previous updates of the coefficient. Less recent velocity data would weigh lighter on the current update while more recent velocity data would weigh heavier. However, this requires we store much more data in terms of the velocity instead of the current method in which the last update is the only point in which we consider.

Regularization:

- Similar to the idea of LASSO and Ridge regression in which we set a threshold in which the sum of coefficients should not exceed, we can do a similar idea when calculating gradients. If the magnitude of the gradient is too high by a threshold the researcher sets, we can reduce the value and ultimately regulate the size of steps taken.

Monitoring:

- A final adjustment we can do is use the loss functions to temper step size during stochastic gradient descent. If the value of the loss function we are using is above a certain threshold or greater than the previous loss, we can reduce how much the momentum contributes to the current update.

## Exercise 2

```{r}
#=========================================================
# Exercise 2
#=========================================================
set.seed(89)

random_coefs <- runif(7, 0,1) # Generate random coefficients

X <- genX_ex2(1000) # Generate x values
y <- genY_ex2(X, random_coefs) # Generate y values

```


```{r ex_2, echo = TRUE}
#set lambda values to loop through
lambdas <- c(0.0001, 0.001, 0.01, 0.1, 1, 10)

#set polynomial degrees to loop through
poly_degrees <- seq(1, 7, by=1)

#set the number of folds
K <- 10

train_optimal_model <- function(x,y){
  # Initialize best lambda, degree, model and test loss to NULL to store optimal parameters and test loss
  best_lambda <- NULL
  best_degree <- NULL
  best_model <- NULL
  best_loss <- Inf
  
  #for each lambda value
  for (lambda in lambdas){
    
    #for each polynomial degree
    for (degree in poly_degrees){
      
      #transform the x data to this particular polynomial
      x_poly <- poly(x, degree)
  
      #assign each observation to a fold
      set.seed(123)
      fold_id <- sample(rep(1:K, each = length(x_poly)/K))
      
      #set the total loss to 0 for this loop
      total_loss <- 0
      
      #for each fold
      for (k in 1:K){
        #assign the validation data for X
        val_X <- x_poly[fold_id == k]
        
        #assign the training data for X
        train_X <- x_poly[fold_id != k]
  
        #assign the validation data for y
        val_y <- y[fold_id == k]
        
        #assign the training data for y
        train_y <- y[fold_id != k]
        
        # Remove any NA values attached to the end of the vector
        val_X <- val_X[!is.na(val_y)]
        train_X <- train_X[!is.na(train_y)]
        val_y <- val_y[!is.na(val_y)]
        train_y <- train_y[!is.na(train_y)]
  
        #create a model with this particular combination of polynomial and lambda using ridge regression
        k_mod <- glmnet(as.matrix(cbind(0,train_X)), train_y, family = "gaussian", lambda = lambda, alpha = 0)
  
        #make predictions with the model
        yhat_k <- predict(k_mod, newx = as.matrix(cbind(0,val_X)), type = "response")
        
        #calculate the loss
        k_loss <- ridgeLoss(val_y, yhat_k, coef(k_mod)[-1], lambda)
  
        #if the loss is less than the best test loss
        if(k_loss < best_loss){
          
            #set the best loss as this value
            best_loss <- k_loss
            
            #set the best degree to this degree
            best_degree <- degree
            
            #set the best lambda to this lambda
            best_lambda <- lambda
            
            #set the best model as this model
            best_model <- k_mod
          }
      }
      
    }
  }
      
    #set the model with all the data
    best_model <- glmnet(cbind(poly(x, best_degree), 0), 
                         y, 
                         family = "gaussian", 
                         lambda = best_lambda, 
                         alpha = 0)
  
    #Print the optimal model
    cat("The best model is: ", "glmnet(x = poly(x, ", 
        best_degree, "), y = y, family = gaussian, alpha = 0, lambda = ", 
        best_lambda, ")", 
        sep="" )
  
    #Print the test loss of the optimal model
    cat("\nThe loss of the optimal model is: ", best_loss)
  
    #return the model with the lowest loss
    return(best_model)
}

optimal_model <- train_optimal_model(X, y) # Train and print model

```

## Exercise 3

Predicting civil wars is of paramount importance due to its implications for global peacekeeping efforts. Research by Hegre et al. (2019) suggests that increased investment in UN peacekeeping efforts could significantly reduce major world conflicts. In their work, in their most ambitious scenario, where UN peacekeeping budgets and mandates were used in their most optimal way, they found that the UN could have transformed four to five conflicts from major conflict to minor conflict in 2013. This represents a 70% reduction in major conflicts that year. Therefore, effectively predicting where civil wars may occur becomes crucial in optimizing the allocation of peacekeeping resources.

For this report, four models were under consideration, KNN, Trees, and LASSO and Ridge regression. KNN and Trees were found to not be suitable for predicting civil wars due to the high dimensionality of the model and their limitations in prediction accuracy, respectively. Consequently, the choice between Ridge and LASSO regression was more pertinent. In this work, LASSO regression was opted for in light of findings from Ward, Greenhill, and Bakke (2010), where they suggested that a parsimonious model, which can be facilitated by LASSO regression, outperforms models with many significantly associated independent and dependent variables in predicting civil war occurrences.

In building the training model, 80% of the data was used for training while the rest was used for testing as per usual division conventions in machine learning.

To assess the performance of the final trained model, a Receiver Operating Characteristic (ROC) curve was employed. The ROC curve provides insights into the trade-off between the true positive rate and false positive rate across different thresholds. A nearly right-angle shape of the curve indicates a low false positive rate and a high true positive rate, suggesting strong predictive performance of the model on unseen data. However, it's important to consider the context that very few civil wars occur in reality. Thus, while the model's performance appears promising, its effectiveness in practical scenarios with limited occurrences of civil wars warrants further examination.


```{r}
#=========================================================
# Exercise 3
#=========================================================
load("civil_wars.RData")

set.seed(123)

predict_civ_war <- function(civwar){
  
  # Set the training index
  train_idx <- sample(1:nrow(civwar), 0.8 * nrow(civwar))
  
  # Set xtrain
  Xtrain <- civwar[train_idx, ]
  # Set x test
  Xtest <- civwar[-train_idx, ]
  
  # Set y train
  ytrain <- Xtrain$war
  
  # Set y test as vector to create ROC curve
  ytest <- as.vector(Xtest$war)
  
  # Remove 'war' column from both training and test sets
  Xtrain <- Xtrain[, -which(names(Xtrain) == "war")]
  Xtest <- Xtest[, -which(names(Xtest) == "war")]
  
  # Use cv.glmnet to estimate the best value for lambda
  lasso_cv <- cv.glmnet(as.matrix(Xtrain), ytrain, alpha = 1)
  
  # Get the value of lambda
  lambda_min <- lasso_cv$lambda.min
  
  # Train final model
  final_mod <- glmnet(as.matrix(Xtrain), ytrain, alpha = 1, lambda = lambda_min)
  
  # Predict test outcomes
  ypred <- predict(final_mod, newx = as.matrix(Xtest))
  ypred <- as.vector(ypred) #set as vector for ROC curve
  
  # Calculate the MSE of test outcomes
  test_loss <- mean((ytest - ypred)^2)
  
  # Calculate ROC curve
  roc_data <- roc(ytest, ypred)
  
  # Plot ROC curve
  plot.roc(roc_data, 
       col = "blue", 
       main = "ROC Curve for Civil War Data", 
       lwd = 2)
  
  return(final_mod)
}

model <- predict_civ_war(civwars) # train model and print ROC curve
```

## References

Brownlee J. (2021, October 12). Gradient Descent With Momentum from Scratch. Machine Learning Mastery. https://machinelearningmastery.com/gradient-descent-with-momentum-from-scratch/

Hegre, H., Hultman, L., & NygÃ¥rd, H. M. (2019). Evaluating the conflict-reducing effect of UN peacekeeping operations. The Journal of Politics, 81(1), 215-232.

Ward, M. D., Greenhill, B. D., & Bakke, K. M. (2010). The perils of policy by p-value: Predicting civil conflicts. Journal of peace research, 47(4), 363-375.

## Appendix: All code in this assignment

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE} 
# this chunk generates the complete code appendix. 
# eval=FALSE tells R not to run (``evaluate'') the code here (it was already run before).
```